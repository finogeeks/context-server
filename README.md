# Agentic SDK Server

> ğŸ¤– æœåŠ¡ç«¯æ™ºèƒ½ä½“è¿è¡Œå¼•æ“ï¼Œä¸ºç§»åŠ¨ç«¯åº”ç”¨æä¾›å¼ºå¤§çš„AIæ™ºèƒ½ä½“èƒ½åŠ›

## æ¦‚è¿°

Agentic SDK Server æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„æœåŠ¡ç«¯ AI æ™ºèƒ½ä½“ç¼–æ’å¼•æ“ï¼Œä¸“ä¸ºç§»åŠ¨ç«¯åº”ç”¨è®¾è®¡ã€‚å®ƒæä¾›äº†å®Œæ•´çš„æ™ºèƒ½ä½“ç”Ÿæ€ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§ä¸“ä¸šåŒ–æ™ºèƒ½ä½“ã€å·¥å…·é›†æˆå’Œå®æ—¶æµå¼å“åº”ã€‚

### æ¶æ„å›¾

```
ç§»åŠ¨ç«¯åº”ç”¨
    â†“ (é›†æˆ)
Agentic SDK (iOS/Android)
    â†“ (SSE é•¿è¿æ¥)
Agentic SDK Server
    â†“ (æ™ºèƒ½ä½“ç¼–æ’)
ä¸“ä¸šåŒ–æ™ºèƒ½ä½“ + MCP å·¥å…·
```

## å¿«é€Ÿå¼€å§‹

### 1. Docker Compose è¿è¡Œ

ç¡®ä¿å·²å®‰è£… Docker å’Œ Docker Composeï¼š

```bash
# æ£€æŸ¥ Docker å®‰è£…
docker --version
docker-compose --version
```

### 2. å…‹éš†å¹¶é…ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-org/agentic-sdk-server.git
cd agentic-sdk-server

# å¤åˆ¶ç¯å¢ƒé…ç½®æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»é…ç½® LLM_API_KEYï¼‰
nano .env
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose logs -f agentic-server
```

### 4. éªŒè¯å®‰è£…

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:3000/health

# æµ‹è¯• API
curl -N -X POST http://localhost:3000/api/agui \
  -H "Content-Type: application/json" \
  -d '{"threadId":"test-001","message":"Hello, how are you?"}'
```

## ç¯å¢ƒé…ç½®

### å¿…éœ€é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­è®¾ç½®ä»¥ä¸‹å¿…éœ€å˜é‡ï¼š

```bash
# LLM æœåŠ¡é…ç½®ï¼ˆå¿…éœ€ï¼‰
LLM_API_KEY=your_llm_api_key_here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4

# æœåŠ¡å™¨ç«¯å£
PORT=3000
```

### é«˜çº§é…ç½®

```bash
# è½»é‡çº§ LLMï¼ˆç”¨äºæ„å›¾è¯†åˆ«ç­‰ç®€å•ä»»åŠ¡ï¼‰
LIGHTWEIGHT_LLM_API_KEY=your_lightweight_llm_api_key
LIGHTWEIGHT_LLM_MODEL=gpt-4o-mini

# æŒä¹…åŒ–æ¨¡å¼
PERSISTENCE_MODE=nats_timescale  # æˆ– memory

# NATS é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰
NATS_SERVERS=nats://localhost:4222
NATS_MAX_RECONNECT=10

# TimescaleDB é…ç½®
TIMESCALE_HOST=localhost
TIMESCALE_DATABASE=agentic_sessions
TIMESCALE_USER=postgres
TIMESCALE_PASSWORD=your_secure_password
```

## API æ–‡æ¡£

### POST /api/agui

æ™ºèƒ½ä½“å¯¹è¯æ¥å£ï¼Œæ”¯æŒ Server-Sent Events (SSE) æµå¼å“åº”ã€‚

#### è¯·æ±‚æ ¼å¼

```json
{
  "threadId": "my-session-id",
  "message": "ä½ å¥½ï¼Œè¯·å¸®æˆ‘å†™ä¸€ä¸ª Python å‡½æ•°"
}
```

#### å“åº”æ ¼å¼

æµå¼ SSE å“åº”ï¼š

**1. å¼€å§‹æ¶ˆæ¯**
```
data: {"type":"start","model":"gpt-4","timestamp":"2025-01-15T10:30:00.000Z"}
```

**2. å†…å®¹ç‰‡æ®µ**ï¼ˆå¤šæ¬¡ï¼‰
```
data: {"type":"chunk","content":"ä½ å¥½","fullContent":"ä½ å¥½"}
data: {"type":"chunk","content":"ï¼æˆ‘å¯ä»¥","fullContent":"ä½ å¥½ï¼æˆ‘å¯ä»¥"}
```

**3. å®Œæˆæ¶ˆæ¯**
```
data: {"type":"done","fullContent":"ä½ å¥½ï¼æˆ‘å¯ä»¥å¸®ä½ å†™Pythonå‡½æ•°...","model":"gpt-4","timestamp":"2025-01-15T10:30:05.000Z"}
```

**4. é”™è¯¯æ¶ˆæ¯**ï¼ˆå¦‚æœæœ‰ï¼‰
```
data: {"type":"error","error":"APIè°ƒç”¨å¤±è´¥","timestamp":"2025-01-15T10:30:02.000Z"}
```

#### ç¤ºä¾‹è¯·æ±‚

```bash
# å®æ—¶æµå¼å¯¹è¯
curl -N -X POST http://localhost:3000/api/agui \
  -H "Content-Type: application/json" \
  -d '{
    "threadId": "chat-session-001",
    "message": "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªé”™è¯¯æ—¥å¿—"
  }'
```

### GET /health

æœåŠ¡å¥åº·æ£€æŸ¥ç«¯ç‚¹ã€‚

```bash
curl http://localhost:3000/health
# å“åº”: {"status":"ok","timestamp":"2025-01-15T10:30:00.000Z"}
```

## éƒ¨ç½²æŒ‡å—

### å¼€å‘ç¯å¢ƒ

ä½¿ç”¨å†…å­˜æ¨¡å¼è¿›è¡Œå¿«é€Ÿå¼€å‘ï¼š

```bash
# .env é…ç½®
PERSISTENCE_MODE=memory
PORT=3000

# å¯åŠ¨
docker-compose up -d agentic-server
```

### ç”Ÿäº§ç¯å¢ƒ

æ¨èä½¿ç”¨å®Œæ•´çš„æŒä¹…åŒ–é…ç½®ï¼š

```bash
# .env ç”Ÿäº§é…ç½®
PERSISTENCE_MODE=nats_timescale
NATS_SERVERS=nats://your-nats-cluster:4222
TIMESCALE_HOST=your-timescale-host
TIMESCALE_PASSWORD=your_secure_password

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

### ç›‘æ§å’Œæ—¥å¿—

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker-compose logs -f agentic-server

# NATS ç›‘æ§é¢æ¿
open http://localhost:7777

# æ•°æ®åº“ç®¡ç†å·¥å…·
open http://localhost:8080
```

## LLM æä¾›å•†æ”¯æŒ

### OpenAI

```bash
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4
LLM_API_KEY=sk-...
```

### Azure OpenAI

```bash
LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
LLM_MODEL=gpt-4
LLM_API_KEY=your-azure-key
```

### å…¶ä»– OpenAI å…¼å®¹æœåŠ¡

```bash
LLM_BASE_URL=https://api.your-service.com/v1
LLM_MODEL=your-model-name
LLM_API_KEY=your-api-key
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. æœåŠ¡å¯åŠ¨å¤±è´¥**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :3000

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
docker-compose logs agentic-server
```

**2. LLM API è°ƒç”¨å¤±è´¥**
```bash
# éªŒè¯ API å¯†é’¥
curl -H "Authorization: Bearer $LLM_API_KEY" \
  https://api.openai.com/v1/models

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec agentic-server ping api.openai.com
```

**3. æ•°æ®åº“è¿æ¥é—®é¢˜**
```bash
# æ£€æŸ¥ TimescaleDB çŠ¶æ€
docker-compose exec timescaledb pg_isready

# æµ‹è¯•è¿æ¥
docker-compose exec agentic-server nc -zv timescaledb 5432
```

### æ€§èƒ½ä¼˜åŒ–

**1. å†…å­˜ä¼˜åŒ–**
```bash
# è°ƒæ•´ TimescaleDB å†…å­˜è®¾ç½®
TS_TUNE_MEMORY=1GB
TS_TUNE_NUM_CPUS=4
```

**2. å¹¶å‘ä¼˜åŒ–**
```bash
# å¢åŠ æ•°æ®åº“è¿æ¥æ± 
TIMESCALE_MAX_CONNECTIONS=50

# NATS è¿æ¥ä¼˜åŒ–
NATS_MAX_RECONNECT=20
NATS_TIMEOUT=10000
```

## å®‰å…¨é…ç½®

### ç”Ÿäº§ç¯å¢ƒå®‰å…¨æ¸…å•

- [ ] æ›´æ”¹é»˜è®¤å¯†ç 
- [ ] é…ç½® HTTPS è¯ä¹¦
- [ ] è®¾ç½®é˜²ç«å¢™è§„åˆ™
- [ ] å¯ç”¨è®¿é—®æ—¥å¿—
- [ ] é…ç½®å¤‡ä»½ç­–ç•¥

### æ¨èå®‰å…¨é…ç½®

```bash
# å¼ºå¯†ç 
POSTGRES_PASSWORD=$(openssl rand -base64 32)

# é™åˆ¶ç½‘ç»œè®¿é—®
# åœ¨ docker-compose.yml ä¸­ç§»é™¤ä¸å¿…è¦çš„ç«¯å£æš´éœ²

# å¯ç”¨ SSL
TIMESCALE_SSL=true
```

## è®¸å¯è¯

MIT License

## æ”¯æŒ

- ğŸ“§ Email: support@your-company.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/your-org/agentic-sdk-server/issues)
- ğŸ“– æ–‡æ¡£: [å®Œæ•´æ–‡æ¡£](https://docs.your-company.com/agentic-sdk-server)

---

**Â© 2025 Your Company. ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚**